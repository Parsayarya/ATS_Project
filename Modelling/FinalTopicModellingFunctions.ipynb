{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "kFoSzOYKfEzi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RFVBn5Pe8Ho"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import LdaModel\n",
        "from gensim.matutils import corpus2csc\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "# import pyLDAvis.gensim\n",
        "# import pickle\n",
        "# import pyLDAvis\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Importing"
      ],
      "metadata": {
        "id": "8ZRoZfAVfBd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/FinalCorpus2.csv')"
      ],
      "metadata": {
        "id": "7EaIWdI_fYdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "PdF9YSoCiqyJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "15e1e919-0a66-4352-a761-ae5634bf6c37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Generated_Name                                               text\n",
              "0       ATCM45_ip001_e.docx  report by the cep observer to the xxxvii scar ...\n",
              "1       ATCM45_ip002_e.docx  report by the ccamlr observer to the forty fif...\n",
              "2  ATCM45_ip003_rev1_e.docx  report by the united kingdom as depositary gov...\n",
              "3       ATCM45_ip004_e.docx  report of the depositary government of the ant...\n",
              "4       ATCM45_ip005_e.docx  republic of belarus in the systemof the antarc..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8465894-b32e-450c-95cf-ac89721977a8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Generated_Name</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ATCM45_ip001_e.docx</td>\n",
              "      <td>report by the cep observer to the xxxvii scar ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ATCM45_ip002_e.docx</td>\n",
              "      <td>report by the ccamlr observer to the forty fif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ATCM45_ip003_rev1_e.docx</td>\n",
              "      <td>report by the united kingdom as depositary gov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ATCM45_ip004_e.docx</td>\n",
              "      <td>report of the depositary government of the ant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ATCM45_ip005_e.docx</td>\n",
              "      <td>republic of belarus in the systemof the antarc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8465894-b32e-450c-95cf-ac89721977a8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a8465894-b32e-450c-95cf-ac89721977a8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a8465894-b32e-450c-95cf-ac89721977a8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a7a050d0-d8f6-4f24-85db-6669cf9949c2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a7a050d0-d8f6-4f24-85db-6669cf9949c2')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a7a050d0-d8f6-4f24-85db-6669cf9949c2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "qS81I56uir4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95c0dc57-c807-4fa2-a3b7-25ecf31bff68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 44907 entries, 0 to 44906\n",
            "Data columns (total 2 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   Generated_Name  44907 non-null  object\n",
            " 1   text            44907 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 701.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning"
      ],
      "metadata": {
        "id": "Fvz4k8E5f5IN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extended_stopwords = stopwords.words('english')"
      ],
      "metadata": {
        "id": "r5O538HJht1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure to download the necessary NLTK data\n",
        "def preprocess_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Preprocess a given text by removing punctuation, special characters, digits,\n",
        "    and then lemmatizing all the words.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): The input text to be preprocessed.\n",
        "\n",
        "    Returns:\n",
        "    str: The preprocessed text.\n",
        "    \"\"\"\n",
        "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    cleaned_text = cleaned_text.lower()\n",
        "    tokens = nltk.word_tokenize(cleaned_text)\n",
        "    extended_stopwords = stopwords.words('english') + SW_list\n",
        "    tokens = [word for word in tokens if word not in extended_stopwords and len(word) > 1]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
        "\n",
        "    return lemmatized_text\n"
      ],
      "metadata": {
        "id": "OstJLNnOhlVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Text_preprocessed'] = df['text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "75UZnbQBh3TA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topic Modelling"
      ],
      "metadata": {
        "id": "ggf4BOVVgBGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scikit Learn LDA"
      ],
      "metadata": {
        "id": "pa0qd6ZIFGQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "\n",
        "def assign_topics_to_dataframe_LDA_V1(df, text_column, n_topics=50, n_top_words=20):\n",
        "    \"\"\"\n",
        "    Read text data from a pandas DataFrame, perform topic modeling,\n",
        "    and assign the main topic (most important words) to each text in a new column.\n",
        "\n",
        "    :param df: Input pandas DataFrame\n",
        "    :param text_column: Name of the column containing text data\n",
        "    :param n_features: The maximum number of features (default is 1000)\n",
        "    :param n_topics: The number of topics to extract (default is 30)\n",
        "    :param n_top_words: The number of top words to extract for each topic (default is 10)\n",
        "\n",
        "    :return: DataFrame with additional columns containing the main topic and scores for each text\n",
        "    \"\"\"\n",
        "    stop_words = stopwords.words('english')\n",
        "    stop_words.extend(SW_list)\n",
        "\n",
        "    count_vectorizer = CountVectorizer(max_df=0.85, min_df=0.10, stop_words=stop_words)\n",
        "    dtm = count_vectorizer.fit_transform(df[text_column])\n",
        "\n",
        "    lda = LatentDirichletAllocation(n_components=n_topics, learning_method='online', learning_offset=50., random_state=1, verbose=1).fit(dtm)\n",
        "\n",
        "    tf_feature_names = count_vectorizer.get_feature_names_out()\n",
        "    topic_dict = {}\n",
        "    for topic_idx, topic in enumerate(lda.components_):\n",
        "        important_features = [tf_feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
        "        topic_dict[topic_idx] = ', '.join(important_features)\n",
        "\n",
        "    topic_assignments = lda.transform(dtm).argmax(axis=1)\n",
        "    topic_scores = lda.transform(dtm)\n",
        "    for i in range(n_topics):\n",
        "        df[f\"Topic {i} Score\"] = topic_scores[:, i]\n",
        "\n",
        "    for topic_idx, topic_words in topic_dict.items():\n",
        "        print(f\"Topic #{topic_idx}: {topic_words}\")\n",
        "\n",
        "    return df\n",
        "df = assign_topics_to_dataframe_LDA_V1(df,'Text_preprocessed')\n",
        "df = df.drop(columns=['Text_preprocessed'])\n",
        "df = df.drop(columns=['text'])\n",
        "df.to_csv('out_Scikit_50_stopwordsExtended_TopicLoadingScores.csv')"
      ],
      "metadata": {
        "id": "jHLGO2y0gD14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gensim Multicore LDA"
      ],
      "metadata": {
        "id": "oxCD6lv_FKuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from gensim import corpora\n",
        "from nltk.corpus import stopwords\n",
        "!python -m spacy download en_core_web_sm\n",
        "import spacy\n",
        "from gensim.models import CoherenceModel\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])"
      ],
      "metadata": {
        "id": "opdE5-gyiaAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in extended_stopwords] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent))\n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "def assign_topics_to_dataframe_LDA_Optimized(df, text_column, n_topics=30, n_top_words=20):\n",
        "    \"\"\"\n",
        "    Read text data from a pandas DataFrame, perform topic modeling,\n",
        "    and assign the main topic (most important words) to each text in a new column.\n",
        "\n",
        "    :param df: Input pandas DataFrame\n",
        "    :param text_column: Name of the column containing text data\n",
        "    :param n_topics: The number of topics to extract (default is 30)\n",
        "    :param n_top_words: The number of top words to extract for each topic (default is 10)\n",
        "\n",
        "    :return: DataFrame with additional columns containing the main topic and scores for each text\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    data = df[text_column].values.tolist()\n",
        "    data_words = list(sent_to_words(data))\n",
        "    bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "    data_words_nostops = remove_stopwords(data_words)\n",
        "    data_words_bigrams = [bigram_mod[doc] for doc in data_words_nostops]\n",
        "    nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
        "    data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "    id2word = corpora.Dictionary(data_lemmatized)\n",
        "    texts = data_lemmatized\n",
        "    corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "    lda = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                     id2word=id2word,\n",
        "                                     num_topics=n_topics,\n",
        "                                     random_state=42,\n",
        "                                     alpha=0.1,\n",
        "                                     eta='auto',\n",
        "                                     chunksize=100,\n",
        "                                     passes=10,\n",
        "                                     per_word_topics=True)\n",
        "\n",
        "    # Assign topics\n",
        "    topic_assignments = []\n",
        "    topic_scores = []\n",
        "    pprint(lda.print_topics())\n",
        "    print('\\n\\n\\n\\n')\n",
        "    topics = lda.show_topics(num_topics=n_topics, num_words=n_top_words, log=False, formatted=False)\n",
        "    for topic_id, topic in topics:\n",
        "        print(f\"Topic: {topic_id}\")\n",
        "        print(f\"Words: {[word for word, _ in topic]}\")\n",
        "    topic_scores_matrix = []\n",
        "\n",
        "    for text in corpus:\n",
        "        topic_prob = lda.get_document_topics(text, minimum_probability=0) # get scores for all topics\n",
        "        topic_scores = [0] * n_topics  # Initialize topic scores with zeros\n",
        "        for topic, score in topic_prob:\n",
        "            topic_scores[topic] = score\n",
        "        topic_scores_matrix.append(topic_scores)\n",
        "    print(topic_scores_matrix,'\\n\\n\\n\\n\\n\\n\\n')\n",
        "\n",
        "    # Add topic scores to the dataframe\n",
        "    for i in range(n_topics):\n",
        "        df.loc[:,f'Topic_{i}_Score'] = [row[i] for row in topic_scores_matrix]\n",
        "    for text in corpus:\n",
        "        topic_prob = lda.get_document_topics(text)\n",
        "        if topic_prob:\n",
        "            topic_prob.sort(key=lambda x: x[1], reverse=True) # sort by probability\n",
        "            topic_assignments.append(topic_prob[0][0])\n",
        "            topic_scores.append(topic_prob[0][1])\n",
        "        else:\n",
        "            topic_assignments.append(None)\n",
        "            topic_scores.append(None)\n",
        "\n",
        "    return df\n",
        "df = assign_topics_to_dataframe_LDA_Optimized(df,'text')\n",
        "df = df.drop(columns=['Text_preprocessed'])\n",
        "df = df.drop(columns=['text'])\n",
        "df.to_csv('out_Gensim_30.csv')"
      ],
      "metadata": {
        "id": "eo62lX5dgLjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reformatting the outputs"
      ],
      "metadata": {
        "id": "ikO8FjX2FRLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Step 1: Read the text file and prepare the data\n",
        "data_dict = {}\n",
        "with open('/content/Topics.txt', 'r') as file:\n",
        "    for line in file:\n",
        "        # Split the line into topic and data, strip any whitespace, and ignore empty lines\n",
        "        line_content = line.strip()\n",
        "        if line_content:  # if line is not empty\n",
        "            topic, data = line_content.split(\":\", 1)  # Only split on the first colon\n",
        "            data_items = [item.strip() for item in data.split(',')]  # Split data into individual pieces\n",
        "\n",
        "            # Store data items under the topic in a dictionary\n",
        "            data_dict[topic.strip()] = data_items\n",
        "\n",
        "# Find the maximum number of rows we'll have in the CSV\n",
        "max_rows = max(len(items) for items in data_dict.values())\n",
        "\n",
        "# Step 2: Write the data to a CSV file\n",
        "with open('/content/Topics.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "\n",
        "    # Write the header (the topics)\n",
        "    writer.writerow(data_dict.keys())\n",
        "\n",
        "    # Write the data rows\n",
        "    for i in range(max_rows):\n",
        "        row = []\n",
        "        for items in data_dict.values():\n",
        "            # Add an item to the row if it exists, otherwise add an empty string\n",
        "            row.append(items[i] if i < len(items) else '')\n",
        "        writer.writerow(row)\n",
        "df_topics = pd.read_csv('/content/Topics.csv')\n",
        "df_topics = df_topics.T\n",
        "df_topics.to_csv('/content/Topics.csv')"
      ],
      "metadata": {
        "id": "C-4Q1kXwpdst"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
